{"cells":[{"source":"<p align=\"center\" width=\"100%\">\n    <img width=\"40%\" src=\"customer_support_icon.JPG\"> \n</p>\n\nA retail company is on a transformative journey, aiming to elevate their customer services through cutting-edge advancements in Speech Recognition and Natural Language Processing (NLP). As the machine learning engineer for this initiative, you are tasked with developing functionalities that not only convert customer support audio calls into text but also explore methodologies to extract insights from transcribed texts.\n\nIn this dynamic project, we leverage the power of `SpeechRecognition`, `Pydub`, and `spaCy` – three open-source packages that form the backbone of your solution. Your objectives are:\n  - Transcribe a sample customer audio call, stored at `sample_customer_call.wav`, to showcase the power of open-source speech recognition technology.\n  - Analyze sentiment, identify common named entities, and enhance user experience by searching for the most similar customer calls based on a given query from a subset of their pre-transcribed call data, stored at `customer_call_transcriptions.csv`.\n\nThis project is an opportunity to unlock the potential of machine learning to revolutionize customer support. Let's delve into the interplay between technology and service excellence.","metadata":{},"id":"d5e81b43-ccfd-4fc6-902c-59cd49aa9913","cell_type":"markdown"},{"source":"!pip install SpeechRecognition\n!pip install pydub\n!pip install spacy\n!python3 -m spacy download en_core_web_sm","metadata":{"executionCancelledAt":null,"executionTime":27397,"lastExecutedAt":1715353552603,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install SpeechRecognition\n!pip install pydub\n!pip install spacy\n!python3 -m spacy download en_core_web_sm","outputsMetadata":{"0":{"height":613,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedByKernel":"73fcac8c-e1d4-470f-a795-8f6224aa345f"},"id":"d0f1598e-18a8-45d5-8387-bf2f5ce4ffd6","cell_type":"code","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: SpeechRecognition in /home/repl/.local/lib/python3.8/site-packages (3.10.4)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.8/dist-packages (from SpeechRecognition) (2.31.0)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from SpeechRecognition) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.26.0->SpeechRecognition) (2019.11.28)\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: pydub in /home/repl/.local/lib/python3.8/site-packages (0.25.1)\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (3.6.1)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.9)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.7)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.8)\nRequirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.8/dist-packages (from spacy) (8.1.12)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.4.7)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.9)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.9.0)\nRequirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.2)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (4.64.0)\nRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.23.2)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.10.12)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.1.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy) (65.6.3)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy) (3.0.9)\nRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.3)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy) (2.1.1)\nDefaulting to user installation because normal site-packages is not writeable\nCollecting en-core-web-sm==3.6.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m115.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\nRequirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\nRequirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.64.0)\nRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.2)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.12)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (65.6.3)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\nRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2019.11.28)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.3)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.1)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n"}]},{"source":"# Import required libraries\nimport pandas as pd\n\nimport nltk\nnltk.download('vader_lexicon')\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nimport speech_recognition as sr\nfrom pydub import AudioSegment\n\nimport spacy","metadata":{"executionCancelledAt":null,"executionTime":9226,"lastExecutedAt":1715353561831,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import required libraries\nimport pandas as pd\n\nimport nltk\nnltk.download('vader_lexicon')\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nimport speech_recognition as sr\nfrom pydub import AudioSegment\n\nimport spacy","outputsMetadata":{"0":{"height":77,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedByKernel":"73fcac8c-e1d4-470f-a795-8f6224aa345f"},"id":"d6f3dd61-8c75-48d4-b2a5-79cd0b444ddb","cell_type":"code","execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":"[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /home/repl/nltk_data...\n"}]},{"source":"#lets convert the sample audio call to text and store the results in transribed_text\n# Define a recognizer object\nrecognizer = sr.Recognizer()\n\n# Convert the audio file to audio data\ntranscribe_audio_file = sr.AudioFile(\"sample_customer_call.wav\")\nwith transcribe_audio_file as source:\n    transcribe_audio = recognizer.record(source)\n\n#convert the audio data into text\ntranscribed_text = recognizer.recognize_google(transcribe_audio)\n#review transcribed text\nprint(\"Transcribed Text: \", transcribed_text)","metadata":{"executionCancelledAt":null,"executionTime":1845,"lastExecutedAt":1715353767302,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#lets convert the sample audio call to text and store the results in transribed_text\n# Define a recognizer object\nrecognizer = sr.Recognizer()\n\n# Convert the audio file to audio data\ntranscribe_audio_file = sr.AudioFile(\"sample_customer_call.wav\")\nwith transcribe_audio_file as source:\n    transcribe_audio = recognizer.record(source)\n\n#convert the audio data into text\ntranscribed_text = recognizer.recognize_google(transcribe_audio)\n#review transcribed text\nprint(\"Transcribed Text: \", transcribed_text)","outputsMetadata":{"0":{"height":59,"type":"stream"}},"lastExecutedByKernel":"73fcac8c-e1d4-470f-a795-8f6224aa345f"},"id":"250524c2-1bd3-4ff8-a224-8fa007566c1b","cell_type":"code","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":"Transcribed Text:  hello I'm experiencing an issue with your product I'd like to speak to someone about a replacement\n"}]},{"source":"# Speech to Text: store few statistics of the audio file such as number of channels, sample width and frame rate\n# review the number of channels and frame rate of the audio_file\naudio_segment = AudioSegment.from_file(\"sample_customer_call.wav\")\nnumber_channels = audio_segment.channels\nframe_rate = audio_segment.frame_rate\n\nprint(\"Number of channels:\", number_channels)\nprint(\"Frame rate:\", frame_rate)","metadata":{"executionCancelledAt":null,"executionTime":17,"lastExecutedAt":1715353979794,"lastExecutedByKernel":"73fcac8c-e1d4-470f-a795-8f6224aa345f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Speech to Text: store few statistics of the audio file such as number of channels, sample width and frame rate\n# review the number of channels and frame rate of the audio_file\naudio_segment = AudioSegment.from_file(\"sample_customer_call.wav\")\nnumber_channels = audio_segment.channels\nframe_rate = audio_segment.frame_rate\n\nprint(\"Number of channels:\", number_channels)\nprint(\"Frame rate:\", frame_rate)","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"cell_type":"code","id":"99ab293d-ba2f-40f9-8b32-7197ba745c97","outputs":[{"output_type":"stream","name":"stdout","text":"Number of channels: 1\nFrame rate: 44100\n"}],"execution_count":12},{"source":"# Sentiment Analysis: use vader module from nltk library to determine the sentiment of each text of the customer_call_transcriptions.csv file and store them at a new sentiment_label column using compound score\ndf = pd.read_csv(\"customer_call_transcriptions.csv\")\n\nsid = SentimentIntensityAnalyzer()\n","metadata":{"executionCancelledAt":null,"executionTime":32,"lastExecutedAt":1715354154794,"lastExecutedByKernel":"73fcac8c-e1d4-470f-a795-8f6224aa345f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Sentiment Analysis: use vader module from nltk library to determine the sentiment of each text of the customer_call_transcriptions.csv file and store them at a new sentiment_label column using compound score\ndf = pd.read_csv(\"customer_call_transcriptions.csv\")\n\nsid = SentimentIntensityAnalyzer()\n"},"cell_type":"code","id":"14f18fce-2a82-46f1-b151-240d5c880990","outputs":[],"execution_count":13},{"source":"# Analyze sentiment by evaluating compound score generated by Vader SentimentIntensityAnalyzer\ndef find_sentiment(text):\n    scores = sid.polarity_scores(text)\n    compound_score = scores['compound']\n\n    if compound_score >= 0.05:\n        return 'positive'\n    elif compound_score <= -0.05:\n        return 'negative'\n    else:\n        return 'neutral'\n\ndf['sentiment_predicted'] = df.apply(lambda row: find_sentiment(row[\"text\"]), axis = 1)","metadata":{"executionCancelledAt":null,"executionTime":40,"lastExecutedAt":1715354184354,"lastExecutedByKernel":"73fcac8c-e1d4-470f-a795-8f6224aa345f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Analyze sentiment by evaluating compound score generated by Vader SentimentIntensityAnalyzer\ndef find_sentiment(text):\n    scores = sid.polarity_scores(text)\n    compound_score = scores['compound']\n\n    if compound_score >= 0.05:\n        return 'positive'\n    elif compound_score <= -0.05:\n        return 'negative'\n    else:\n        return 'neutral'\n\ndf['sentiment_predicted'] = df.apply(lambda row: find_sentiment(row[\"text\"]), axis = 1)"},"cell_type":"code","id":"9d0714bb-adc0-44d8-98c4-1fb320ccaa40","outputs":[],"execution_count":14},{"source":"\n# Task 2 - Sentiment Analysis: calculate number of texts with positive label that are correctly labeled as positive\ntrue_positive = len(df.loc[(df['sentiment_predicted'] == df['sentiment_label']) &\n                (df['sentiment_label'] == 'positive')])\n\nprint(\"True positives: \", true_positive)\n","metadata":{"executionCancelledAt":null,"executionTime":13,"lastExecutedAt":1715354199449,"lastExecutedByKernel":"73fcac8c-e1d4-470f-a795-8f6224aa345f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"\n# Task 2 - Sentiment Analysis: calculate number of texts with positive label that are correctly labeled as positive\ntrue_positive = len(df.loc[(df['sentiment_predicted'] == df['sentiment_label']) &\n                (df['sentiment_label'] == 'positive')])\n\nprint(\"True positives: \", true_positive)\n","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"2207382d-d10c-4f20-96cb-d9f85347c933","outputs":[{"output_type":"stream","name":"stdout","text":"True positives:  2\n"}],"execution_count":15},{"source":"# Task 3 - Named Entity Recognition: find named entities for each text in the df object and store entities in a named_entities column\n\n# Load spaCy small English Language model\nnlp = spacy.load(\"en_core_web_sm\")\n\n# NER using spaCy\ndef extract_entities(text):\n    doc = nlp(text)\n    entities = [ent.text for ent in doc.ents]\n    return entities\n","metadata":{"executionCancelledAt":null,"executionTime":467,"lastExecutedAt":1715354220416,"lastExecutedByKernel":"73fcac8c-e1d4-470f-a795-8f6224aa345f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Task 3 - Named Entity Recognition: find named entities for each text in the df object and store entities in a named_entities column\n\n# Load spaCy small English Language model\nnlp = spacy.load(\"en_core_web_sm\")\n\n# NER using spaCy\ndef extract_entities(text):\n    doc = nlp(text)\n    entities = [ent.text for ent in doc.ents]\n    return entities\n"},"cell_type":"code","id":"0e22c1b1-cfa3-4bce-aa25-e7b66e87aa03","outputs":[],"execution_count":16},{"source":"# Apply NER to the entire text column\ndf['named_entities'] = df['text'].apply(extract_entities)\n\n# Flatten the list of named entities\nall_entities = [ent for entities in df['named_entities'] for ent in entities]\n\n# Create a DataFrame with the counts\nentities_df = pd.DataFrame(all_entities, columns=['entity'])\nentities_counts = entities_df['entity'].value_counts().reset_index()\nentities_counts.columns = ['entity', 'count']\n\n# Extract most frequent named entity\nmost_freq_ent = entities_counts[\"entity\"].iloc[0]\nprint(\"Most frequent entity: \", most_freq_ent)","metadata":{"executionCancelledAt":null,"executionTime":609,"lastExecutedAt":1715354233103,"lastExecutedByKernel":"73fcac8c-e1d4-470f-a795-8f6224aa345f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Apply NER to the entire text column\ndf['named_entities'] = df['text'].apply(extract_entities)\n\n# Flatten the list of named entities\nall_entities = [ent for entities in df['named_entities'] for ent in entities]\n\n# Create a DataFrame with the counts\nentities_df = pd.DataFrame(all_entities, columns=['entity'])\nentities_counts = entities_df['entity'].value_counts().reset_index()\nentities_counts.columns = ['entity', 'count']\n\n# Extract most frequent named entity\nmost_freq_ent = entities_counts[\"entity\"].iloc[0]\nprint(\"Most frequent entity: \", most_freq_ent)","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"0f196b20-538a-47e7-bde9-63eee02e38fb","outputs":[{"output_type":"stream","name":"stdout","text":"Most frequent entity:  yesterday\n"}],"execution_count":17},{"source":"# Task 4 - Find most similar text: find the list of customer calls that complained about \"wrong package delivery\" by finding similarity score of each text to the \"wrong package delivery\" string using spaCy small English Language model\n\n# Load spaCy model\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Process the text column\ndf['processed_text'] = df['text'].apply(lambda text: nlp(text))\n\n# Input query\ninput_query = \"wrong package delivery\"\nprocessed_query = nlp(input_query)\n\n# Calculate similarity scores and sort dataframe with respect to similarity scores\ndf['similarity'] = df['processed_text'].apply(lambda text: processed_query.similarity(text))\ndf = df.sort_values(by='similarity', ascending=False)\n\n# Find the most similar text\nmost_similar_text = df[\"text\"].iloc[0]\nprint(\"Most similar text: \", most_similar_text)","metadata":{"executionCancelledAt":null,"executionTime":1022,"lastExecutedAt":1715354249455,"lastExecutedByKernel":"73fcac8c-e1d4-470f-a795-8f6224aa345f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Task 4 - Find most similar text: find the list of customer calls that complained about \"wrong package delivery\" by finding similarity score of each text to the \"wrong package delivery\" string using spaCy small English Language model\n\n# Load spaCy model\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Process the text column\ndf['processed_text'] = df['text'].apply(lambda text: nlp(text))\n\n# Input query\ninput_query = \"wrong package delivery\"\nprocessed_query = nlp(input_query)\n\n# Calculate similarity scores and sort dataframe with respect to similarity scores\ndf['similarity'] = df['processed_text'].apply(lambda text: processed_query.similarity(text))\ndf = df.sort_values(by='similarity', ascending=False)\n\n# Find the most similar text\nmost_similar_text = df[\"text\"].iloc[0]\nprint(\"Most similar text: \", most_similar_text)","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"9b338284-c1ac-4ea9-918c-7efb8c17f0ba","outputs":[{"output_type":"stream","name":"stdout","text":"Most similar text:  wrong package delivered\n"}],"execution_count":18}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}